{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_sizes(*data_sets):\n",
    "    max_sent_size = max_ques_size = max_fact_count = 0\n",
    "    for data in data_sets:\n",
    "        for x, q, fc in zip(data.xs, data.qs, data.fact_counts):\n",
    "            for fact in x: max_sent_size = max(max_sent_size, len(fact))\n",
    "            max_ques_size = max(max_ques_size, len(q))\n",
    "            max_fact_count = max(max_fact_count, fc)\n",
    "\n",
    "    return max_sent_size, max_ques_size, max_fact_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    source_dir = os.path.join(home, \"data\", \"squad\")\n",
    "    target_dir = \"home/Rishab/Desktop//data/squad\"\n",
    "    glove_dir = os.path.join(home, \"data\", \"glove\")\n",
    "    parser.add_argument('-s', \"--source_dir\", default=source_dir)\n",
    "    parser.add_argument('-t', \"--target_dir\", default=target_dir)\n",
    "    parser.add_argument('-d', \"--debug\", action='store_true')\n",
    "    parser.add_argument(\"--train_ratio\", default=0.9, type=int)\n",
    "    parser.add_argument(\"--glove_corpus\", default=\"6B\")\n",
    "    parser.add_argument(\"--glove_dir\", default=glove_dir)\n",
    "    parser.add_argument(\"--glove_vec_size\", default=100, type=int)\n",
    "    parser.add_argument(\"--mode\", default=\"full\", type=str)\n",
    "    parser.add_argument(\"--single_path\", default=\"\", type=str)\n",
    "    parser.add_argument(\"--tokenizer\", default=\"PTB\", type=str)\n",
    "    parser.add_argument(\"--url\", default=\"vision-server2.corp.ai2\", type=str)\n",
    "    parser.add_argument(\"--port\", default=8000, type=int)\n",
    "    parser.add_argument(\"--split\", action='store_true')\n",
    "    # TODO : put more args here\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open(\"/home/Rishab/Desktop/squad/data/sequence/train.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Architecturally , the school has a Catholic character . Atop the Main Building 's gold dome is a golden statue of the Virgin Mary . Immediately in front of the Main Building and facing it , is a copper statue of Christ with arms upraised with the legend `` Venite Ad Me Omnes '' . Next to the Main Building is the Basilica of the Sacred Heart . Immediately behind the basilica is the Grotto , a Marian place of prayer and reflection . It is a replica of the grotto at Lourdes , France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858 . At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ) , is a simple , modern stone statue of Mary .\\tWhat is in front of the Notre Dame Main Building ?\\t38 39 40 41 42\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=f.readline()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38 39 40 41 42\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\"\\t\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "cv=nltk.word_tokenize(x)\n",
    "cnt=-1\n",
    "for i in cv:\n",
    "    cnt+=1\n",
    "    print(i,cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepSQuAD():\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "    import json\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    count = 0\n",
    "    filenames = ['dev', 'train']\n",
    "    for filename in filenames:\n",
    "        fpr = open(\"/home/Rishab/Desktop/squad/data/\"+filename+\"-v1.1.json\", 'r')\n",
    "        line = fpr.readline()\n",
    "        js = json.loads(line)\n",
    "        fpw = open(\"/home/Rishab/Desktop/squad/data/sequence/\"+filename+\".txt\", 'wr')\n",
    "        for c in js[\"data\"]:\n",
    "            for p in c[\"paragraphs\"]:\n",
    "                context = p[\"context\"].split(' ')\n",
    "                context_char = list(p[\"context\"])\n",
    "                context_pos = {}\n",
    "                for qa in p[\"qas\"]:\n",
    "                    question = word_tokenize(qa[\"question\"])\n",
    "                    if filename == 'train':\n",
    "                        for a in qa['answers']:\n",
    "                            answer = a['text'].strip()\n",
    "                            answer_start = int(a['answer_start'])\n",
    "                            answer_words = word_tokenize(answer+'.')\n",
    "                            if answer_words[-1] == '.':\n",
    "                                answer_words = answer_words[:-1]\n",
    "                            else:\n",
    "                                answer_words = word_tokenize(answer)\n",
    "                        prev_context_words = word_tokenize( p[\"context\"][0:answer_start ] )\n",
    "                        left_context_words = word_tokenize( p[\"context\"][answer_start:] )\n",
    "                        answer_reproduce = []\n",
    "                        for i in range(len(answer_words)):\n",
    "                            if i < len(left_context_words):\n",
    "                                w = left_context_words[i]\n",
    "                                answer_reproduce.append(w)\n",
    "                        join_a = ' '.join(answer_words)\n",
    "                        join_ar = ' '.join(answer_reproduce)\n",
    "                        if join_a != join_ar:\n",
    "                            count += 1\n",
    "                        fpw.write(' '.join(prev_context_words+left_context_words)+'\\t')\n",
    "                        fpw.write(' '.join(question)+'\\t')\n",
    "                        \n",
    "                        pos_list = []\n",
    "                        for i in range(len(answer_words)):\n",
    "                            if i < len(left_context_words):\n",
    "                                pos_list.append(str(len(prev_context_words)+i+1))\n",
    "                        if len(pos_list) == 0:\n",
    "                            print join_ar\n",
    "                            print join_a\n",
    "                            print 'answer:'+answer\n",
    "                        assert(len(pos_list) > 0)\n",
    "                        fpw.write(' '.join(pos_list)+'\\n')\n",
    "                    else:\n",
    "                        fpw.write(' '.join(word_tokenize( p[\"context\"]) )+'\\t')\n",
    "                        fpw.write(' '.join(question)+'\\n')\n",
    "                \n",
    "\n",
    "        fpw.close()\n",
    "    print ('SQuAD preprossing finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "opt.model = 'boundaryMPtr'\n",
    "opt.task = 'squad'\n",
    "opt.log = 'log information'\n",
    "opt.visualize = false\n",
    "opt.numWords = 124164\n",
    "torch.manualSeed(opt.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_integer(\"batch_size\",6,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"wvecdim\",300,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"mem_dim\",150,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"att_dim\",150,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"num_processes\",5,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"max_epoches\",30,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"seed\",123,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"reg\",0,\"\")\n",
    "tf.app.flags.DEFINE_boolean(\"visualize\",False,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"numwords\",124164,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"num_layers\",1,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"m_layers\",2,\"\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\",0.002,\"\")\n",
    "tf.app.flags.DEFINE_float(\"lr_decay\",0.002,\"\")\n",
    "tf.app.flags.DEFINE_float(\"dropoutP\",0.4,\"\")\n",
    "tf.app.flags.DEFINE_integer(\"emb_lr\",0,\"\")\n",
    "tf.app.flags.DEFINE_string(\"preEmb\",\"glove\",\"\")\n",
    "tf.app.flags.DEFINE_string(\"grad\",\"adamax\",\"\")\n",
    "tf.app.flags.DEFINE_integer(\"expIdx\",0,\"\")\n",
    "tf.app.flags.DEFINE_boolean(\"inititlaUNK\",False,\"\")\n",
    "tf.app.flags.DEFINE_boolean(\"emb_partial\",True,\"\")\n",
    "\n",
    "FLAGS=tf.app.flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Question'):\n",
    "            ques_list = tf.unpack(tf.transpose(question))\n",
    "            ques_embed = [tf.nn.embedding_lookup(embedding, w) for w in ques_list]\n",
    "            _, question_vec = tf.nn.rnn(gru, ques_embed, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_dims(shape):\n",
    "    fan_in = shape[0] if len(shape) == 2 else np.prod(shape[:-1])\n",
    "    fan_out = shape[1] if len(shape) == 2 else shape[-1]\n",
    "    return fan_in, fan_out\n",
    "\n",
    "def weight(name, shape, init='he', range=None):\n",
    "    \n",
    "    initializer = tf.constant_initializer()\n",
    "    if init == 'xavier':\n",
    "        fan_in, fan_out = _get_dims(shape)\n",
    "        range = math.sqrt(6.0 / (fan_in + fan_out))\n",
    "        initializer = tf.random_uniform_initializer(-range, range)\n",
    "\n",
    "    elif init == 'he':\n",
    "        fan_in, _ = _get_dims(shape)\n",
    "        std = math.sqrt(2.0 / fan_in)\n",
    "        initializer = tf.random_normal_initializer(stddev=std)\n",
    "\n",
    "    \n",
    "    var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    tf.add_to_collection('l2', tf.nn.l2_loss(var)) \n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias(name, dim, initial_value=0.0):\n",
    "    dims = dim if isinstance(dim, list) else [dim]\n",
    "    return tf.get_variable(name, dims, initializer=tf.constant_initializer(initial_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"apple\"):\n",
    "    cell=rnn_cell.LSTMCell(100,state_is_tuple=True)\n",
    "    H_paara = tf.placeholder(tf.float32, shape=[40, 60 , 80 ], name='para') \n",
    "    axx,_=tf.nn.dynamic_rnn(cell,H_paara,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen=tf.placeholder(tf.int32,[64],\"ghyu\")\n",
    "with tf.variable_scope(\"amipoom\"):\n",
    "    H_par4a = tf.placeholder(tf.float32, shape=[64, 20 , 80 ], name='para') \n",
    "    embedding = weight('di789aoosd', [100, 80], init='uniform', range=3**(1/2))\n",
    "    cell=rnn_cell.LSTMCell(80,state_is_tuple=True)\n",
    "    para_list=tf.unpack(tf.transpose(H_para))\n",
    "    para_embed=[tf.nn.embedding_lookup(embedding,w) for w in para_list]\n",
    "    xPara , _ =tf.nn.dynamic_rnn(cell,H_par4a,seqlen,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'amipoom/RNN/transpose:0' shape=(64, 20, 80) dtype=float32>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xPara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-cc6fbb45a706>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-cc6fbb45a706>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    for i in the range of\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DMN(BaseModel):\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        N=\"batch size\"; P=\"para length\"; Q=\"ques length\"; aa=\"answ length\"\n",
    "        V=\"words embedding size\"\n",
    "        A=\"words vocab length\"\n",
    "        d=\"hidden size\"\n",
    "        \n",
    "        H_para = tf.placeholder('int32', shape=[N, P , V ], name='para') \n",
    "        H_ques = tf.placeholder('int32', shape=[N, Q , V], name='ques')  \n",
    "        H_answ = tf.placeholder('int32', shape=[N, aa], name='answ')\n",
    "        \n",
    "        \n",
    "        para_mask = tf.placeholder('float32', shape=[N, P, V], name='para_m')\n",
    "        ques_mask = tf.placeholder('float32', shape=[N, Q, V], name='ques_m')\n",
    "        \n",
    "                \n",
    "        # Prepare parameters\n",
    "        cell = rnn_cell.LSTMCell(d,state_is_tuple=True)\n",
    "        #l = self.positional_encoding()\n",
    "        embedding = weight('embedding', [A, V], init='uniform', range=3**(1/2))\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "        with tf.variable_scope('Para'):\n",
    "            para_list=tf.unpack(tf.transpose(H_para))\n",
    "            para_embed=[tf.nn.embedding_lookup(embedding,w) for w in para_list]\n",
    "            \n",
    "            Para , _ =tf.nn.dynamic_rnn(cell,H_para,dtype=tf.float32) # [batch_size, para_length , hidden_state(d)]\n",
    "            #Para, para_state = tf.nn.rnn(cell, para_embed, dtype=tf.float32)  # [ batch_size, hidden_state ]\n",
    "            \n",
    "        with tf.variable_scope('ques'):\n",
    "            ques_list=tf.unpack(tf.transpose(H_ques))\n",
    "            ques_embed=[tf.nn.embedding_lookup(embedding,w) for w in ques_list]\n",
    "            Ques , _ =tf.nn.dynamic_rnn(cell,H_ques,dtype=tf.float32) # [batch_size, ques_length , hidden_state(d)]\n",
    "            \n",
    "            Ques, Ques_state = tf.nn.rnn(cell, ques_embed, dtype=tf.float32) # [ batch_size, hidden_state ]\n",
    "        \n",
    "\n",
    "        \n",
    "        MatchLstm()\n",
    "        Answerpointer()\n",
    "        \n",
    "\n",
    "        with tf.name_scope('Loss'):\n",
    "            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, answer)\n",
    "            loss = tf.reduce_mean(cross_entropy)\n",
    "            total_loss = loss + params.weight_decay * tf.add_n(tf.get_collection('l2'))\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HR = weight('hr', [d, 1])\n",
    "class MatchLstm():\n",
    "    def __init__(self, num_hidden, question, facts, is_training, bn):\n",
    "        self.WQ = weight('wq', [num_hidden, num_hidden])\n",
    "        self.WP = weight('wp', [num_hidden, num_hidden])\n",
    "        self.WR = weight('wr', [num_hidden, num_hidden])\n",
    "        self.HR = weight('hr', [num_hidden, 1])\n",
    "        self.b =  weight('b' ,  [1])\n",
    "        self.bp = bias('bp', [num_hidden, 1])\n",
    "        self.w  = bias('w',  [num_hidden, 1])\n",
    "        self.b = bias('b', 1)\n",
    "        self.facts_transposed = [tf.transpose(f) for f in self.facts]  \n",
    "        \n",
    "    def init_state(self):\n",
    "        return tf.zeros_like(self.facts_transposed[0])\n",
    "    \n",
    "    def cal_hidd():\n",
    "        t_cell=rnn_cell.BasicLSTMCell(self.num_hidden)\n",
    "        with tf.variable_scope(''):\n",
    "            #calculation of G\n",
    "            WQXHQ = tf.matmul(self.WQ, Ques)\n",
    "            WPXHP  =  tf.matmul(self.WP, h_para)\n",
    "            WPXHP +=  tf.matmul(self.WR, hr)\n",
    "            WPXHP +=  self.bp\n",
    "            l1= tf.tile(WPXHP , [1, Q] )  #[ hidden_size , question_length ]\n",
    "            l_g=tf.nn.tanh(l1)\n",
    "            \n",
    "            #calculation of alpha\n",
    "            \n",
    "            wt = tf.transpose(self.w)       #[1 , hidden_size     ]\n",
    "            l2 = tf.matmul(wt,l_g)          #[1 , question_length ]\n",
    "            leq = tf.tile(self.b , [1, Q])  #[1 , question_length ]\n",
    "            l_alpha = tf.nn.softmax(l2 + leq)  #[1 , question_length ]\n",
    "            \n",
    "            \n",
    "            #calculation of z\n",
    "            \n",
    "            t_alpha=tf.transpose(l_alpha)\n",
    "            temp_var=tf.matmul(self.ques,t_alpha)  #[hidden_state , 1]\n",
    "            #temp_z=tf.concat(0,[h_para,temp_var]) # to be discussed later\n",
    "            with tf.variable_scope('final_hidden') as final_h_scope:\n",
    "                cell = rnn_cell.LSTMCell(d,state_is_tuple=True)\n",
    "                temp_z=tf.transpose(temp_var)\n",
    "                _, hidden_state = tf.nn.rnn(cell, [temp_z], dtype=tf.float32)\n",
    "                final_h_scope.reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Answer_pointer():\n",
    "    \n",
    "    def __init__(hidden_size,H_r):\n",
    "        self.V  =  weight('V', [ hidden_size, 2*hidden_size ])\n",
    "        self.WA =  weight('WA',[ hidden_size, hidden_size ])\n",
    "        self.ba =  weight('ba',[ hidden_size, 1 ])\n",
    "        self.v  =  weight('v',[ hidden_size, 1 ])\n",
    "        self.facts_transposed = [tf.transpose(f) for f in self.facts]\n",
    "        self.ze_ten = tf.zeros([hidden_size,1])\n",
    "        self.H_r = H_r\n",
    "        self.H_rr = tf.concat(1, [self.H_r,self.ze_ten] )\n",
    "        self.c =    weight('c',[ 1 ])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def init_state(self):\n",
    "        return tf.zeros_like(self.facts_transposed[0])\n",
    "    \n",
    "    def cal_ans(H_r):\n",
    "        \n",
    "        # calcualtion of FK\n",
    "        l1   = tf.matmul(self.WA , self.HA)\n",
    "        l1+  = self.ba\n",
    "        lep1 = tf.tile( l1 , [1 , (P+1) ])\n",
    "        \n",
    "        l2  = tf.matmul(self.V, self.H_rr)\n",
    "        lf2 = l2 + lep1\n",
    "        \n",
    "        #calculation of  beta\n",
    "        temp_vfk = tf.matmul(tf.transpose(self.v), lf2 )\n",
    "        temp_cfk = tf.tile(self.c , [1,(P+1) ])\n",
    "        beta  = tf.nn.softmax(temp_vfk + temp_cfk)\n",
    "        \n",
    "        #calculation of Hak\n",
    "        \n",
    "        beta_t = tf.transpose(beta)\n",
    "        temp_h = tf.matmul(self.H_rr,beta_t )  # [ 2* hidden_size , 1]\n",
    "        \n",
    "        with tf.variable_scope(\"\"):\n",
    "            cell = rnn_cell.LSTMCell(d,state_is_tuple=True)\n",
    "            temp_z=tf.transpose(temp_var)\n",
    "            _, hidden_state = tf.nn.rnn(cell, [temp_z], dtype=tf.float32)\n",
    "            final_h_scope.reuse_variables()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rft= tf.placeholder('int32',[40,8])\n",
    "rt = tf.placeholder('int32',[40,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state_variables(batch_size, cell):\n",
    "    state_variables = []\n",
    "    for state_c, state_h in cell.zero_state(batch_size, tf.float32):\n",
    "        state_variables.append(tf.nn.rnn_cell.LSTMStateTuple(\n",
    "            tf.Variable(state_c, trainable=False),\n",
    "            tf.Variable(state_h, trainable=False)))\n",
    "    return tuple(state_variables)\n",
    "\n",
    "\n",
    "def get_state_update_op(state_variables, new_states):\n",
    "    update_ops = []\n",
    "    for state_variable, new_state in zip(state_variables, new_states):\n",
    "        update_ops.extend([state_variable[0].assign(new_state[0]),\n",
    "                           state_variable[1].assign(new_state[1])])\n",
    "    return tf.tuple(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(tf.float32, (batch_size, max_length, frame_size))\n",
    "cell_layer = tf.nn.rnn_cell.GRUCell(256)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)\n",
    "\n",
    "states = get_state_variables(batch_size, cell)\n",
    "outputs, new_states = tf.nn.dynamic_rnn(cell, data, initial_state=states)\n",
    "update_op = get_state_update_op(states, new_states)\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'RNN_2/BasicLSTMCell/mul_2:0' shape=(8, 4) dtype=float32>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat=tf.placeholder(tf.int16,[3,2])\n",
    "tah=tf.placeholder(tf.int16,[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_28:0' shape=(6, 2) dtype=int16>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(0,[hat,tah])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.bias>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = bias('ad', 80 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "axd = weight('axd', [80, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(80), Dimension(1)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axd.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'as_1:0' shape=(80, 1) dtype=int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.placeholder(\"int32\", [80,1],'as')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H_para = tf.placeholder('int32', shape=[64, 20, 80 ], name='para') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = rnn_cell.BasicLSTMCell(60)\n",
    "embedding = weight('embedding', [800, 80], init='uniform', range=3**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "used = tf.sign(tf.reduce_max(tf.abs(H_para), reduction_indices=2))\n",
    "length = tf.cast(tf.reduce_sum(used, reduction_indices=1), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Sign:0' shape=(64, 20) dtype=int32>,\n",
       " <tf.Tensor 'Sum:0' shape=(64,) dtype=int32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tf.reshape(tf.transpose(tf.pack(output), perm=[1, 0, 2]), [-1,  60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(1280, 120) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'concat:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_1:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_2:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_3:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_4:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_5:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_6:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_7:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_8:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_9:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_10:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_11:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_12:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_13:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_14:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_15:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_16:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_17:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_18:0' shape=(64, 120) dtype=float32>,\n",
       " <tf.Tensor 'concat_19:0' shape=(64, 120) dtype=float32>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'para:0' shape=(64, 20, 80) dtype=int32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(64,) dtype=int32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vrc=np.zeros([64,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing()\n",
    "match_lstm()\n",
    "answer_ponter()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#self.params.embed_size, self.params.max_sent_size, self.params.batch_size\n",
    "def positional_encoding():\n",
    "        D=80\n",
    "        M=20  \n",
    "        N=64\n",
    "        encoding = np.zeros([M, D])\n",
    "        for j in range(M):\n",
    "            for d in range(D):\n",
    "                encoding[j, d] = (1 - float(j)/M) - (float(d)/D)*(1 - 2.0*j/M)\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 80)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N F L \n",
    "\n",
    "N=64            #batch size\n",
    "F=1            #fact_count\n",
    "L=20           #max sent size\n",
    "d=80            #hidden dimension\n",
    "V=80            #word embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_para = tf.placeholder('int32', shape=[N, F , L ], name='para') \n",
    "input_mask = tf.placeholder('float32', shape=[N, F, L, V], name='xm')\n",
    "embedding = weight('em64', [100, V], init='uniform', range=3**(1/2))\n",
    "\n",
    "with tf.name_scope('SentenceReader'):\n",
    "    input_list = tf.unpack(tf.transpose(H_para))  \n",
    "    input_embed = []\n",
    "    for facts in input_list:\n",
    "        facts = tf.unpack(facts)\n",
    "        embed = tf.pack([tf.nn.embedding_lookup(embedding, w) for w in facts]) \n",
    "        input_embed.append(embed)\n",
    "\n",
    "        \n",
    "l=positional_encoding()\n",
    "\n",
    "input_embed = tf.transpose(tf.pack(input_embed), [2, 1, 0, 3])  # [N, F, L, V]\n",
    "encoded = l * input_embed * input_mask\n",
    "facts = tf.reduce_sum(encoded, 2)  # [N, F, V]\n",
    "\n",
    "            \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = rnn_cell.GRUCell(d)\n",
    "fact_cout = tf.placeholder('int64', shape=[N], name='fc')\n",
    "with tf.name_scope('InputFu'):\n",
    "    with tf.variable_scope('Forw'):\n",
    "        forward_tas, _ = tf.nn.dynamic_rnn(gru, facts, fact_cout, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'InputFu/Forw/RNN/transpose:0' shape=(64, 20, 80) dtype=float32>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(64, 12, 60) dtype=float32>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'ert/RNN/BasicLSTMCell/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_1/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_2/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_3/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_4/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_5/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_6/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_7/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_8/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_9/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_10/mul_2:0' shape=(64, 80) dtype=float32>,\n",
       " <tf.Tensor 'ert/RNN/BasicLSTMCell_11/mul_2:0' shape=(64, 80) dtype=float32>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
